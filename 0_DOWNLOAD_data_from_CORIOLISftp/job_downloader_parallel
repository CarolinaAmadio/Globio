#!/bin/bash

#SBATCH --job-name=globio
#SBATCH -N 1 
#SBATCH --ntasks-per-node=4 
#SBATCH --time=4:00:00
#SBATCH --account=OGS23_PRACE_IT
#SBATCH --partition=g100_all_serial

BASEDIR=/g100_work/OGS_devC/camadio/GLOBIO/

HOST=ftp.ifremer.fr
USER=anonymous
REMOTEDIR=/ifremer/argo/
LOCALDIR=$BASEDIR/CORIOLIS/download/tmp

INDEXER_CORIOLIS=$BASEDIR/CORIOLIS/download/Global_floats.txt
NAMEINDEXFILE=$BASEDIR/argo_synthetic-profile_index.txt

mkdir -p $BASEDIR/CORIOLIS $BASEDIR/CORIOLIS/download/ $LOCALDIR
# ssh login10


if [ -f $NAMEINDEXFILE ] ; then
    rm $NAMEINDEXFILE
fi

# 1. Downloading of file argo_synthetic-profile_index.txt
wget https://data-argo.ifremer.fr/$NAMEINDEXFILE
# 2. cancel files with lat lon blanks and discard descending profiles 
grep -v ",," $NAMEINDEXFILE | grep -v D.nc > $BASEDIR/argo_synthetic-profile_index_CORR.txt

source /g100_work/OGS23_PRACE_IT/COPERNICUS/py_env_3.9.18/bin/activate

if [ -f $INDEXER_CORIOLIS ] ; then
    rm $INDEXER_CORIOLIS
fi

# 3. arrange file argo_synthetic-profile_index_CORR.txt removing header
python argo_reader_modified.py -i $BASEDIR/argo_synthetic-profile_index_CORR.txt -o $INDEXER_CORIOLIS

export PATH=$PATH:/g100_work/OGS23_PRACE_IT/COPERNICUS/bin
REMOTEDIR=/ifremer/argo/dac/

export REMOTEDIR=$REMOTEDIR
export HOST=$HOST
export USER=$USER 
export LOCALDIR=$LOCALDIR

# 4. downloading of the data 
awk -F, '{print $1}' "$INDEXER_CORIOLIS" | xargs -P12 -I {} bash -c '
    FULL_PATH="{}"
    NAMEFILE="${FULL_PATH##*/}"

    if [ -f "$LOCALDIR/${NAMEFILE}" ]; then
        echo "$LOCALDIR/${NAMEFILE} already exists, skipping download."
    else
        /g100_work/OGS23_PRACE_IT/COPERNICUS/bin/ncftpget -u "$USER" "$HOST" "$LOCALDIR" "$REMOTEDIR/{}"
        echo "Process $BASHPID has finished downloading $NAMEFILE in $LOCALDIR"
    fi
'

echo "NetCDF files have been downloaded. Now, perform count checks before arranging the structure of the CORIOLIS directory and creating Float_Index.txt"

